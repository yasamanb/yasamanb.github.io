<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Features</div>
<div class="menu-item"><a href="index.html" class="current">About</a></div>
<div class="menu-item"><a href="CVpage.html">Curriculum&nbsp;Vitae</a></div>
<div class="menu-item"><a href="current.html">Machine&nbsp;Learning&nbsp;Research</a></div>
<div class="menu-item"><a href="past.html">Physics&nbsp;Research</a></div>
<div class="menu-item"><a href="pubs.html">Publication&nbsp;List</a></div>
</td>
<td id="layout-content">
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="photo.jpg" alt="alt text" width="225px" height="250px" /></a>&nbsp;</td>
<td align="left"><h1>Yasaman Bahri  <br /> </h1>
<p><b>Research Scientist</b> <br />
<b>Google Research</b> (<b>Brain Team</b>) <br /></p>
</td></tr></table>
<p><br /></p>
<p>I am theoretical scientist working at the boundary of machine learning and the physical sciences. <br /></p>
<p>On the one hand, I am interested in scientific questions and general principles within machine learning. In this direction, I have been working on building a theoretical and empirical understanding of deep learning that will be useful for a broad range of communities. In the reverse direction, I am interested in using machine learning to advance the physical sciences, focused on condensed matter physics and materials science. <br /> <br /> </p>
<p>A sample of topics from some of my past & ongoing work in this area includes:</p>
<ul>
<li><p>Theoretical and empirical understanding of the role of scale in deep learning (&lsquo;&lsquo;scaling laws") </p>
</li>
<li><p>Exact connections between deep neural networks, Gaussian processes, and kernel methods</p>
</li>
<li><p>Phase transitions and the dynamics of gradient descent in supervised deep learning</p>
</li>
<li><p>Connections between information propagation in deep neural networks, neural network priors, and trainability</p>
</li>
<li><p>Distribution shift and the pre-training, fine-tuning paradigm </p>
</li>
<li><p>Graph neural networks for prediction in molecular physics</p>
</li>
</ul>
<p><br /> </p>
<p>See a recent <a href="https://www.quantamagazine.org/a-new-link-to-an-old-model-could-crack-the-mystery-of-deep-learning-20211011/">Quanta magazine article</a> for coverage on older work.</p>
<p>I was trained as a theoretical quantum condensed matter physicist, and I received my Ph.D. in Physics from UC Berkeley in 2017. My graduate work is specifically in the field of quantum many-body theory and strongly correlated physics. I was fortunate to have Professor <a href="https://www.physics.harvard.edu/people/facpages/vishwanath">Ashvin Vishwanath</a> as my thesis advisor. My scientific interests have always been broad, and I worked on several different areas as part of my doctoral research, including topological phases, many-body localization, and non-Fermi liquids. My dissertation proposed new classes of quantum behavior; new routes towards realizing exotic quantum phases; and new classes of mechanical behavior through topological mechanisms. I got started in theory as an undergraduate through research on tensor networks and entanglement in quantum systems with Professor <a href="http://cmt.berkeley.edu/jemoore">Joel Moore</a> at UC Berkeley, which was also the subject of my honors senior thesis. <br /></p>
<p><a href="https://scholar.google.com/citations?user=p2_vHmAAAAAJ&amp;hl=en&amp;oi=ao">Link to Google Scholar</a> <br /></p>
<p>Contact: yasamanbahri@gmail.com, yasamanb@google.com</p>
<h2>Recent News</h2>
<ul>
<li><p>Gave a guest lecture in CS 159 at Caltech on theoretical aspects of deep learning. <br /></p>
</li>
</ul>
<ul>
<li><p>I am co-organizer for the ICML 2021 workshop, <a href="https://sites.google.com/view/icml2021oppo">Overparameterization: Pitfalls &amp; Opportunities.</a> <br /> </p>
</li>
</ul>
<ul>
<li><p>We have posted a new preprint: <a href="https://arxiv.org/abs/2102.06701">&lsquo;&lsquo;Explaining Neural Scaling Laws."</a> </p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2021-11-04 19:53:38 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
