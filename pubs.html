<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publication List</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Features</div>
<div class="menu-item"><a href="index.html" class="current">About</a></div>
<div class="menu-item"><a href="CVpage.html">Curriculum&nbsp;Vitae</a></div>
<div class="menu-item"><a href="current.html">Machine&nbsp;Learning&nbsp;Research</a></div>
<div class="menu-item"><a href="past.html">Physics&nbsp;Research</a></div>
<div class="menu-item"><a href="pubs.html">Publication&nbsp;List</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publication List</h1>
</div>
<p>[1]. <a href="https://arxiv.org/abs/2102.06701">&ldquo;Explaining Neural Scaling Laws&rdquo;</a> <br />
<b>Yasaman Bahri</b>, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma <br /> 
<i>(Alphabetical order</i>) <br /> 
Under review <br /></p>
<p>[2]. <a href="https://arxiv.org/abs/2003.02218">&ldquo;The large learning rate phase of deep learning: the catapult mechanism&rdquo;</a> <br />
Aitor Lewkowycz, <b>Yasaman Bahri</b>, Ethan Dyer, Jascha Sohl-Dickstein, Guy Gur-Ari <br /> 
In submission <br /></p>
<p>[3]. <a href="http://proceedings.mlr.press/v119/hron20a">&ldquo;Infinite-attention: NNGP and NTK for deep attention networks&rdquo;</a> <br />
Jiri Hron, <b>Yasaman Bahri</b>, Jascha Sohl-Dickstein, Roman Novak  <br />
ICML 2020 (International Conference on Machine Learning)<br /></p>
<p>[4]. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-conmatphys-031119-050745">&ldquo;Statistical Mechanics of Deep Learning&rdquo;</a> <br />
<b>Yasaman Bahri</b>, Jonathan Kadmon, Jeffrey Pennington, Sam S. Schoenholz, Jascha Sohl-Dickstein, Surya Ganguli <br />
Annual Review of Condensed Matter Physics (2020) <br /></p>
<p>[5]. <a href="https://papers.nips.cc/paper/2019/hash/0d1a9651497a38d8b1c3871c84528bd4-Abstract.html">&ldquo;Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent&rdquo;</a> <br />
Jaehoon Lee*, Lechao Xiao*, Sam S. Schoenholz, <b>Yasaman Bahri</b>, Jascha Sohl-Dickstein, Jeffrey Pennington <br />
NeurIPS 2019 (Advances in Neural Information Processing Systems) <br />
Also published in Journal of Statistical Mechanics: Theory and Experiment (2020) 124002 <br /></p>
<p>[6]. <a href="https://arxiv.org/abs/1810.05148">&ldquo;Bayesian Convolutional Neural Networks with Many Channels are Gaussian Processes&rdquo;</a> <br />
Roman Novak, Lechao Xiao, Jaehoon Lee*, <b>Yasaman Bahri</b>*, Greg Yang, Jiri Hron, Dan Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein <br />
*Equal contribution <br />
ICLR 2019 (International Conference on Learning Representations) <br /></p>
<p>[7]. <a href="https://arxiv.org/abs/1806.05393">&ldquo;Dynamical isometry and a mean field theory of convolutional networks: how to train 10,000-layer vanilla CNNs&rdquo;</a> <br />
Lechao Xiao, <b>Yasaman Bahri</b>, Jascha Sohl-Dickstein, Sam S. Schoenholz, Jeffrey Pennington <br />
ICML 2018 (International Conference on Machine Learning) <br /></p>
<p>[8]. <a href="https://arxiv.org/abs/1711.00165">&ldquo;Deep Neural Networks as Gaussian Processes&rdquo;</a> <br />
Jaehoon Lee*, <b>Yasaman Bahri</b>*, Roman Novak, Sam S. Schoenholz, Jeffrey Pennington, Jascha Sohl-Dickstein <br />
*<i>Equal contribution</i> <br />
ICLR 2018 (International Conference on Learning Representations) <br /></p>
<p>[9]. <a href="https://arxiv.org/abs/1802.08760">&ldquo;Sensitivity and Generalization in Neural Networks: an Empirical Study&rdquo;</a> <br />
Roman Novak, <b>Yasaman Bahri</b>, Dan Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein <br />
ICLR 2018 (International Conference on Learning Representations) <br /></p>
<p>[10]. <a href="http://proceedings.mlr.press/v70/pennington17a">&ldquo;Geometry of Neural Network Loss Surfaces via Random Matrix Theory&rdquo;</a> <br />
Jeffrey Pennington and <b>Yasaman Bahri</b> <br />
ICML 2017 (International Conference on Machine Learning)</p>
<p>[11].  Hoi Chun Po, <b>Yasaman Bahri</b>, and Ashvin Vishwanath. &ldquo;Phonon analog of topological nodal semimetals.&rdquo; <a href="http://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.205158">Phys. Rev. B. 93, 205158 (2016)</a>. <b>Editor's Suggestion</b><br /></p>
<p>[12]. <b>Yasaman Bahri</b> and Andrew C. Potter. &ldquo;Stable non-Fermi-liquid phase of itinerant spin-orbit coupled ferromagnets.&rdquo; <a href="http://journals.aps.org/prb/abstract/10.1103/PhysRevB.92.035131">Phys. Rev. B 92, 035131 (2015)</a>. <br /></p>
<p>[13].  <b>Yasaman Bahri</b>, Ronen Vosk, Ehud Altman, and Ashvin Vishwanath. &ldquo;Localization and topology protected quantum coherence at the edge of hot matter.&rdquo; <a href="http://www.nature.com/articles/ncomms8341">Nature Communications 6:7341 (2015)</a>. <br /></p>
<p>[14].  <b>Yasaman Bahri</b> and Ashvin Vishwanath. &ldquo;Detecting Majorana fermions in quasi-one-dimensional topological phases using nonlocal order parameters.&rdquo; <a href="http://journals.aps.org/prb/abstract/10.1103/PhysRevB.89.155135">Phys. Rev. B 89, 155135 (2014)</a>. </p>
<div id="footer">
<div id="footer-text">
Page generated 2021-05-01 18:13:17 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="pubs.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
